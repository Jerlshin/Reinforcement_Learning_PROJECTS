{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1073ae28",
   "metadata": {},
   "source": [
    "## Tune an LLM with RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8bc26",
   "metadata": {},
   "source": [
    "The RLHF training process has been implemented in a machine learning pipeline as part of the (Google Cloud Pipeline Components) library. This can be run on any platform that supports KubeFlow Pipelines (an open source framework), and can also run on Google Cloud's Vertex AI Pipelines.\n",
    "\n",
    "\n",
    "* google-cloud-pipeline-components\n",
    "* kfp    # KubeFlow Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce326bc",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Using VertexAI fro GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c7818",
   "metadata": {},
   "source": [
    "### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8289be-0f03-4f97-aaf3-b4e80330bce9",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# RLHF is currently in preview\n",
    "from google_cloud_pipeline_components.preview.llm \\\n",
    "import rlhf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ac4718-782d-4fe7-a39f-51fe5b423210",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# KubeFlow pipelines\n",
    "from kfp import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef016774-5400-45be-9682-4b0b0daa9095",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# path to the yaml file\n",
    "RLHF_PIPELINE_PKG_PATH = \"rlhf_pipeline.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abca02b-c43b-4301-8be0-a34949eb38b0",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# compile function from kfp.compiler.Compiler().compile()\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=rlhf_pipeline,  # the pipeline we are using \n",
    "    package_path=RLHF_PIPELINE_PKG_PATH  # to store the yaml file, no need to edit this file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3904e2b-593c-4c95-b0c8-f7334a1fa728",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# PIPELINE DEFINITION\r\n",
      "# Name: rlhf-train-template\r\n",
      "# Description: Performs reinforcement learning from human feedback.\r\n",
      "# Inputs:\r\n",
      "#    deploy_model: bool [Default: True]\r\n",
      "#    eval_dataset: str\r\n",
      "#    instruction: str\r\n",
      "#    kl_coeff: float [Default: 0.1]\r\n",
      "#    large_model_reference: str\r\n",
      "#    location: str [Default: '{{$.pipeline_google_cloud_location}}']\r\n"
     ]
    }
   ],
   "source": [
    "!head rlhf_pipeline.yaml  # printing first few lines (head) of yaml file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951da6e9",
   "metadata": {},
   "source": [
    "**Note**: to print the whole YAML file, use the following:\n",
    "```Python\n",
    "!cat rlhf_pipeline.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14851c",
   "metadata": {},
   "source": [
    "## Vertex AI pipeline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe574a96",
   "metadata": {},
   "source": [
    "#### Location of the training and evaluation data and other params\n",
    "Datasets are in Google Cloud Storage and in JSON lines format. The datasets should be stored in same GCS bucket. \n",
    "\n",
    "- GCS - Google Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff91eb",
   "metadata": {},
   "source": [
    "### Calculate the number of reward model training steps\n",
    "\n",
    "- reward model train steps depends on the size of the dataset, atleast 20-30 would be better\n",
    "\n",
    "$$ stepsPerEpoch = \\left\\lceil \\frac{datasetSize}{batchSize} \\right\\rceil$$\n",
    "$$ trainSteps = stepsPerEpoch \\times numEpochs$$\n",
    "\n",
    "* dividing the dataset into batches\n",
    "* trainsteps means no of batches, so the no of train steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1031a7d-ed33-451b-aac4-1e1b616826c4",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Preference dataset size\n",
    "PREF_DATASET_SIZE = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7cbe0db-19de-4b0b-bfd7-8bd06a22defa",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # it is fixed, can't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8c94da3-3016-4743-baeb-50bedd330328",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dfb58a8-9498-41b3-afc8-7ef81c4a7404",
   "metadata": {
    "height": 61
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "REWARD_STEPS_PER_EPOCH = math.ceil(PREF_DATASET_SIZE / BATCH_SIZE)\n",
    "print(REWARD_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbe291d6-6d5c-4fb8-a783-61fb21269766",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "REWARD_NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f83ffdc9-29d6-40e7-be30-06693816de63",
   "metadata": {
    "height": 61
   },
   "outputs": [],
   "source": [
    "# Calculate number of steps in the reward model training\n",
    "reward_model_train_steps = REWARD_STEPS_PER_EPOCH * REWARD_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1f3df46-868f-470f-b4db-bbcd4ca6dfd2",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410\n"
     ]
    }
   ],
   "source": [
    "print(reward_model_train_steps)   # just paractical stufff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e866f-828e-4d5b-9d42-d206b57cb0b9",
   "metadata": {},
   "source": [
    "### Calculate the number of reinforcement learning training steps\n",
    "\n",
    "- Reward hacking: if given too many training steps, the policy model may figure out a way to exploit the reward and exhibit undesired behavior.\n",
    "\n",
    "Very bad uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6880ae3-8977-4605-9b8d-e50013c03896",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Prompt dataset size\n",
    "PROMPT_DATASET_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08e1f705-9ff2-4204-b4f9-96bcaacf798c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Batch size is fixed at 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30281c30-3b29-4ec0-b7fc-0df4f0203349",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "RL_STEPS_PER_EPOCH = math.ceil(PROMPT_DATASET_SIZE / BATCH_SIZE)\n",
    "print(RL_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3415a4c5-c816-46e1-8b1e-2b6b976f2653",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "RL_NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d16b09f-5e48-4c2e-bb33-0b719e0943fa",
   "metadata": {
    "height": 61
   },
   "outputs": [],
   "source": [
    "# Calculate the number of steps in the RL training\n",
    "reinforcement_learning_train_steps = RL_STEPS_PER_EPOCH * RL_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4079f9-0816-46c3-937f-3c85a491eb22",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "print(reinforcement_learning_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b95cf-9f6f-45c2-810f-363f761a235b",
   "metadata": {},
   "source": [
    "\n",
    "- same instruction as in the preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aa85831",
   "metadata": {
    "height": 315
   },
   "outputs": [],
   "source": [
    "# Completed values for the dictionary\n",
    "parameter_values={\n",
    "    # preference dataset and path \n",
    "        \"preference_dataset\": \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "    # prompt datasets\n",
    "        \"prompt_dataset\": \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "    # we can also use eval dataset\n",
    "        \"eval_dataset\": \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "    # the base LLM we have to tune \n",
    "        \"large_model_reference\": \"llama-2-7b\",   \n",
    "    # this train step says how well it has been finetuned\n",
    "        \"reward_model_train_steps\": 1410, \n",
    "        \"reinforcement_learning_train_steps\": 320, \n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 1.0,\n",
    "        \"kl_coeff\": 0.1,   # increased to reduce reward hacking\n",
    "        \"instruction\": \"Summarize in less than 50 words\"}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e973740",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'utils' has 36 lines.\n"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode\n",
    "with open(\"utils.py\", \"r\") as file:\n",
    "    # Read the lines from the file\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    # Count the number of lines\n",
    "    num_lines = len(lines)\n",
    "    \n",
    "    # Print the number of lines\n",
    "    print(f\"The file 'utils' has {num_lines} lines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a820b9b6-d93c-492c-8e0f-7570d4bc67c1",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Authenticate in utils\n",
    "from utils import authenticate\n",
    "credentials, PROJECT_ID, STAGING_BUCKET = authenticate()\n",
    "\n",
    "REGION = \"europe-west4\"  # RLHF pipeline available in this region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "202343ed",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def authenticate():\n",
      "    #Load .env\n",
      "    load_dotenv()\n",
      "    #DLAI Custom Key\n",
      "    return \"DLAI_CREDENTIALS\", \"DLAI_PROJECT\", \"gs://gcp-sc2-rlhf\"\n",
      "    \n",
      "    #Decode key and store in .JSON\n",
      "    SERVICE_ACCOUNT_KEY_STRING_B64 = os.getenv('SERVICE_ACCOUNT_KEY')\n",
      "    SERVICE_ACCOUNT_KEY_BYTES_B64 = SERVICE_ACCOUNT_KEY_STRING_B64.encode(\"ascii\")\n",
      "    SERVICE_ACCOUNT_KEY_STRING_BYTES = base64.b64decode(SERVICE_ACCOUNT_KEY_BYTES_B64)\n",
      "    SERVICE_ACCOUNT_KEY_STRING = SERVICE_ACCOUNT_KEY_STRING_BYTES.decode(\"ascii\")\n",
      "\n",
      "    SERVICE_ACCOUNT_KEY = json.loads(SERVICE_ACCOUNT_KEY_STRING)\n",
      "\n",
      "\n",
      "    # Create credentials based on key from service account\n",
      "    # Make sure your account has the roles listed in the Google Cloud Setup section\n",
      "    credentials = Credentials.from_service_account_info(\n",
      "        SERVICE_ACCOUNT_KEY,\n",
      "        scopes=['https://www.googleapis.com/auth/cloud-platform'])\n",
      "\n",
      "    if credentials.expired:\n",
      "        credentials.refresh(Request())\n",
      "    \n",
      "    #Set project ID according to environment variable    \n",
      "    PROJECT_ID = os.getenv('PROJECT_ID')\n",
      "    STAGING_BUCKET = os.getenv('STAGING_BUCKET')# 'gs://gcp-sc2-rlhf-staging'\n",
      "    \n",
      "    return credentials, PROJECT_ID, STAGING_BUCKET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "source_code = inspect.getsource(authenticate)\n",
    "print(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92c675b6",
   "metadata": {
    "height": 250
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Credentials\n",
      "class Credentials(\n",
      "    credentials.Signing,\n",
      "    credentials.Scoped,\n",
      "    credentials.CredentialsWithQuotaProject,\n",
      "    credentials.CredentialsWithTokenUri,\n",
      "):\n",
      "    \"\"\"Service account credentials\n",
      "\n",
      "    Usually, you'll create these credentials with one of the helper\n",
      "    constructors. To create credentials using a Google service account\n",
      "    private key JSON file::\n",
      "\n",
      "        credentials = service_account.Credentials.from_service_account_file(\n",
      "            'service-account.json')\n",
      "\n",
      "    Or if you already have the service account file loaded::\n",
      "\n",
      "        service_account_info = json.load(open('service_account.json'))\n",
      "        credentials = service_account.Credentials.from_service_account_info(\n",
      "            service_account_info)\n",
      "\n",
      "    Both helper methods pass on arguments to the constructor, so you can\n",
      "    specify additional scopes and a subject if necessary::\n",
      "\n",
      "        credentials = service_account.Credentials.from_service_account_file(\n",
      "            'service-account.json',\n",
      "            scopes=['email'],\n",
      "            subject='user@example.com')\n",
      "\n",
      "    The credentials are considered immutable. If you want to modify the scopes\n",
      "    or the subject used for delegation, use :meth:`with_scopes` or\n",
      "    :meth:`with_subject`::\n",
      "\n",
      "        scoped_credentials = credentials.with_scopes(['email'])\n",
      "        delegated_credentials = credentials.with_subject(subject)\n",
      "\n",
      "    To add a quota project, use :meth:`with_quota_project`::\n",
      "\n",
      "        credentials = credentials.with_quota_project('myproject-123')\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        signer,\n",
      "        service_account_email,\n",
      "        token_uri,\n",
      "        scopes=None,\n",
      "        default_scopes=None,\n",
      "        subject=None,\n",
      "        project_id=None,\n",
      "        quota_project_id=None,\n",
      "        additional_claims=None,\n",
      "        always_use_jwt_access=False,\n",
      "        universe_domain=_DEFAULT_UNIVERSE_DOMAIN,\n",
      "        trust_boundary=None,\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            signer (google.auth.crypt.Signer): The signer used to sign JWTs.\n",
      "            service_account_email (str): The service account's email.\n",
      "            scopes (Sequence[str]): User-defined scopes to request during the\n",
      "                authorization grant.\n",
      "            default_scopes (Sequence[str]): Default scopes passed by a\n",
      "                Google client library. Use 'scopes' for user-defined scopes.\n",
      "            token_uri (str): The OAuth 2.0 Token URI.\n",
      "            subject (str): For domain-wide delegation, the email address of the\n",
      "                user to for which to request delegated access.\n",
      "            project_id  (str): Project ID associated with the service account\n",
      "                credential.\n",
      "            quota_project_id (Optional[str]): The project ID used for quota and\n",
      "                billing.\n",
      "            additional_claims (Mapping[str, str]): Any additional claims for\n",
      "                the JWT assertion used in the authorization grant.\n",
      "            always_use_jwt_access (Optional[bool]): Whether self signed JWT should\n",
      "                be always used.\n",
      "            universe_domain (str): The universe domain. The default\n",
      "                universe domain is googleapis.com. For default value self\n",
      "                signed jwt is used for token refresh.\n",
      "            trust_boundary (str): String representation of trust boundary meta.\n",
      "\n",
      "        .. note:: Typically one of the helper constructors\n",
      "            :meth:`from_service_account_file` or\n",
      "            :meth:`from_service_account_info` are used instead of calling the\n",
      "            constructor directly.\n",
      "        \"\"\"\n",
      "        super(Credentials, self).__init__()\n",
      "\n",
      "        self._scopes = scopes\n",
      "        self._default_scopes = default_scopes\n",
      "        self._signer = signer\n",
      "        self._service_account_email = service_account_email\n",
      "        self._subject = subject\n",
      "        self._project_id = project_id\n",
      "        self._quota_project_id = quota_project_id\n",
      "        self._token_uri = token_uri\n",
      "        self._always_use_jwt_access = always_use_jwt_access\n",
      "        if not universe_domain:\n",
      "            self._universe_domain = _DEFAULT_UNIVERSE_DOMAIN\n",
      "        else:\n",
      "            self._universe_domain = universe_domain\n",
      "\n",
      "        if universe_domain != _DEFAULT_UNIVERSE_DOMAIN:\n",
      "            self._always_use_jwt_access = True\n",
      "\n",
      "        self._jwt_credentials = None\n",
      "\n",
      "        if additional_claims is not None:\n",
      "            self._additional_claims = additional_claims\n",
      "        else:\n",
      "            self._additional_claims = {}\n",
      "        self._trust_boundary = \"0\"\n",
      "\n",
      "    @classmethod\n",
      "    def _from_signer_and_info(cls, signer, info, **kwargs):\n",
      "        \"\"\"Creates a Credentials instance from a signer and service account\n",
      "        info.\n",
      "\n",
      "        Args:\n",
      "            signer (google.auth.crypt.Signer): The signer used to sign JWTs.\n",
      "            info (Mapping[str, str]): The service account info.\n",
      "            kwargs: Additional arguments to pass to the constructor.\n",
      "\n",
      "        Returns:\n",
      "            google.auth.jwt.Credentials: The constructed credentials.\n",
      "\n",
      "        Raises:\n",
      "            ValueError: If the info is not in the expected format.\n",
      "        \"\"\"\n",
      "        return cls(\n",
      "            signer,\n",
      "            service_account_email=info[\"client_email\"],\n",
      "            token_uri=info[\"token_uri\"],\n",
      "            project_id=info.get(\"project_id\"),\n",
      "            universe_domain=info.get(\"universe_domain\", _DEFAULT_UNIVERSE_DOMAIN),\n",
      "            trust_boundary=info.get(\"trust_boundary\"),\n",
      "            **kwargs\n",
      "        )\n",
      "\n",
      "    @classmethod\n",
      "    def from_service_account_info(cls, info, **kwargs):\n",
      "        \"\"\"Creates a Credentials instance from parsed service account info.\n",
      "\n",
      "        Args:\n",
      "            info (Mapping[str, str]): The service account info in Google\n",
      "                format.\n",
      "            kwargs: Additional arguments to pass to the constructor.\n",
      "\n",
      "        Returns:\n",
      "            google.auth.service_account.Credentials: The constructed\n",
      "                credentials.\n",
      "\n",
      "        Raises:\n",
      "            ValueError: If the info is not in the expected format.\n",
      "        \"\"\"\n",
      "        signer = _service_account_info.from_dict(\n",
      "            info, require=[\"client_email\", \"token_uri\"]\n",
      "        )\n",
      "        return cls._from_signer_and_info(signer, info, **kwargs)\n",
      "\n",
      "    @classmethod\n",
      "    def from_service_account_file(cls, filename, **kwargs):\n",
      "        \"\"\"Creates a Credentials instance from a service account json file.\n",
      "\n",
      "        Args:\n",
      "            filename (str): The path to the service account json file.\n",
      "            kwargs: Additional arguments to pass to the constructor.\n",
      "\n",
      "        Returns:\n",
      "            google.auth.service_account.Credentials: The constructed\n",
      "                credentials.\n",
      "        \"\"\"\n",
      "        info, signer = _service_account_info.from_filename(\n",
      "            filename, require=[\"client_email\", \"token_uri\"]\n",
      "        )\n",
      "        return cls._from_signer_and_info(signer, info, **kwargs)\n",
      "\n",
      "    @property\n",
      "    def service_account_email(self):\n",
      "        \"\"\"The service account email.\"\"\"\n",
      "        return self._service_account_email\n",
      "\n",
      "    @property\n",
      "    def project_id(self):\n",
      "        \"\"\"Project ID associated with this credential.\"\"\"\n",
      "        return self._project_id\n",
      "\n",
      "    @property\n",
      "    def requires_scopes(self):\n",
      "        \"\"\"Checks if the credentials requires scopes.\n",
      "\n",
      "        Returns:\n",
      "            bool: True if there are no scopes set otherwise False.\n",
      "        \"\"\"\n",
      "        return True if not self._scopes else False\n",
      "\n",
      "    def _make_copy(self):\n",
      "        cred = self.__class__(\n",
      "            self._signer,\n",
      "            service_account_email=self._service_account_email,\n",
      "            scopes=copy.copy(self._scopes),\n",
      "            default_scopes=copy.copy(self._default_scopes),\n",
      "            token_uri=self._token_uri,\n",
      "            subject=self._subject,\n",
      "            project_id=self._project_id,\n",
      "            quota_project_id=self._quota_project_id,\n",
      "            additional_claims=self._additional_claims.copy(),\n",
      "            always_use_jwt_access=self._always_use_jwt_access,\n",
      "            universe_domain=self._universe_domain,\n",
      "        )\n",
      "        return cred\n",
      "\n",
      "    @_helpers.copy_docstring(credentials.Scoped)\n",
      "    def with_scopes(self, scopes, default_scopes=None):\n",
      "        cred = self._make_copy()\n",
      "        cred._scopes = scopes\n",
      "        cred._default_scopes = default_scopes\n",
      "        return cred\n",
      "\n",
      "    def with_always_use_jwt_access(self, always_use_jwt_access):\n",
      "        \"\"\"Create a copy of these credentials with the specified always_use_jwt_access value.\n",
      "\n",
      "        Args:\n",
      "            always_use_jwt_access (bool): Whether always use self signed JWT or not.\n",
      "\n",
      "        Returns:\n",
      "            google.auth.service_account.Credentials: A new credentials\n",
      "                instance.\n",
      "        Raises:\n",
      "            google.auth.exceptions.InvalidValue: If the universe domain is not\n",
      "                default and always_use_jwt_access is False.\n",
      "        \"\"\"\n",
      "        cred = self._make_copy()\n",
      "        if (\n",
      "            cred._universe_domain != _DEFAULT_UNIVERSE_DOMAIN\n",
      "            and not always_use_jwt_access\n",
      "        ):\n",
      "            raise exceptions.InvalidValue(\n",
      "                \"always_use_jwt_access should be True for non-default universe domain\"\n",
      "            )\n",
      "        cred._always_use_jwt_access = always_use_jwt_access\n",
      "        return cred\n",
      "\n",
      "    def with_subject(self, subject):\n",
      "        \"\"\"Create a copy of these credentials with the specified subject.\n",
      "\n",
      "        Args:\n",
      "            subject (str): The subject claim.\n",
      "\n",
      "        Returns:\n",
      "            google.auth.service_account.Credentials: A new credentials\n",
      "                instance.\n",
      "        \"\"\"\n",
      "        cred = self._make_copy()\n",
      "        cred._subject = subject\n",
      "        return cred\n",
      "\n",
      "    def with_claims(self, additional_claims):\n",
      "        \"\"\"Returns a copy of these credentials with modified claims.\n",
      "\n",
      "        Args:\n",
      "            additional_claims (Mapping[str, str]): Any additional claims for\n",
      "                the JWT payload. This will be merged with the current\n",
      "                additional claims.\n",
      "\n",
      "        Returns:\n",
      "            google.auth.service_account.Credentials: A new credentials\n",
      "                instance.\n",
      "        \"\"\"\n",
      "        new_additional_claims = copy.deepcopy(self._additional_claims)\n",
      "        new_additional_claims.update(additional_claims or {})\n",
      "        cred = self._make_copy()\n",
      "        cred._additional_claims = new_additional_claims\n",
      "        return cred\n",
      "\n",
      "    @_helpers.copy_docstring(credentials.CredentialsWithQuotaProject)\n",
      "    def with_quota_project(self, quota_project_id):\n",
      "        cred = self._make_copy()\n",
      "        cred._quota_project_id = quota_project_id\n",
      "        return cred\n",
      "\n",
      "    @_helpers.copy_docstring(credentials.CredentialsWithTokenUri)\n",
      "    def with_token_uri(self, token_uri):\n",
      "        cred = self._make_copy()\n",
      "        cred._token_uri = token_uri\n",
      "        return cred\n",
      "\n",
      "    def _make_authorization_grant_assertion(self):\n",
      "        \"\"\"Create the OAuth 2.0 assertion.\n",
      "\n",
      "        This assertion is used during the OAuth 2.0 grant to acquire an\n",
      "        access token.\n",
      "\n",
      "        Returns:\n",
      "            bytes: The authorization grant assertion.\n",
      "        \"\"\"\n",
      "        now = _helpers.utcnow()\n",
      "        lifetime = datetime.timedelta(seconds=_DEFAULT_TOKEN_LIFETIME_SECS)\n",
      "        expiry = now + lifetime\n",
      "\n",
      "        payload = {\n",
      "            \"iat\": _helpers.datetime_to_secs(now),\n",
      "            \"exp\": _helpers.datetime_to_secs(expiry),\n",
      "            # The issuer must be the service account email.\n",
      "            \"iss\": self._service_account_email,\n",
      "            # The audience must be the auth token endpoint's URI\n",
      "            \"aud\": _GOOGLE_OAUTH2_TOKEN_ENDPOINT,\n",
      "            \"scope\": _helpers.scopes_to_string(self._scopes or ()),\n",
      "        }\n",
      "\n",
      "        payload.update(self._additional_claims)\n",
      "\n",
      "        # The subject can be a user email for domain-wide delegation.\n",
      "        if self._subject:\n",
      "            payload.setdefault(\"sub\", self._subject)\n",
      "\n",
      "        token = jwt.encode(self._signer, payload)\n",
      "\n",
      "        return token\n",
      "\n",
      "    def _use_self_signed_jwt(self):\n",
      "        # Since domain wide delegation doesn't work with self signed JWT. If\n",
      "        # subject exists, then we should not use self signed JWT.\n",
      "        return self._subject is None and self._jwt_credentials is not None\n",
      "\n",
      "    def _metric_header_for_usage(self):\n",
      "        if self._use_self_signed_jwt():\n",
      "            return metrics.CRED_TYPE_SA_JWT\n",
      "        return metrics.CRED_TYPE_SA_ASSERTION\n",
      "\n",
      "    @_helpers.copy_docstring(credentials.Credentials)\n",
      "    def refresh(self, request):\n",
      "        if (\n",
      "            self._universe_domain != _DEFAULT_UNIVERSE_DOMAIN\n",
      "            and not self._jwt_credentials\n",
      "        ):\n",
      "            raise exceptions.RefreshError(\n",
      "                \"self._jwt_credentials is missing for non-default universe domain\"\n",
      "            )\n",
      "        if self._universe_domain != _DEFAULT_UNIVERSE_DOMAIN and self._subject:\n",
      "            raise exceptions.RefreshError(\n",
      "                \"domain wide delegation is not supported for non-default universe domain\"\n",
      "            )\n",
      "\n",
      "        if self._use_self_signed_jwt():\n",
      "            self._jwt_credentials.refresh(request)\n",
      "            self.token = self._jwt_credentials.token.decode()\n",
      "            self.expiry = self._jwt_credentials.expiry\n",
      "        else:\n",
      "            assertion = self._make_authorization_grant_assertion()\n",
      "            access_token, expiry, _ = _client.jwt_grant(\n",
      "                request, self._token_uri, assertion\n",
      "            )\n",
      "            self.token = access_token\n",
      "            self.expiry = expiry\n",
      "\n",
      "    def _create_self_signed_jwt(self, audience):\n",
      "        \"\"\"Create a self-signed JWT from the credentials if requirements are met.\n",
      "\n",
      "        Args:\n",
      "            audience (str): The service URL. ``https://[API_ENDPOINT]/``\n",
      "        \"\"\"\n",
      "        # https://google.aip.dev/auth/4111\n",
      "        if self._always_use_jwt_access:\n",
      "            if self._scopes:\n",
      "                additional_claims = {\"scope\": \" \".join(self._scopes)}\n",
      "                if (\n",
      "                    self._jwt_credentials is None\n",
      "                    or self._jwt_credentials.additional_claims != additional_claims\n",
      "                ):\n",
      "                    self._jwt_credentials = jwt.Credentials.from_signing_credentials(\n",
      "                        self, None, additional_claims=additional_claims\n",
      "                    )\n",
      "            elif audience:\n",
      "                if (\n",
      "                    self._jwt_credentials is None\n",
      "                    or self._jwt_credentials._audience != audience\n",
      "                ):\n",
      "\n",
      "                    self._jwt_credentials = jwt.Credentials.from_signing_credentials(\n",
      "                        self, audience\n",
      "                    )\n",
      "            elif self._default_scopes:\n",
      "                additional_claims = {\"scope\": \" \".join(self._default_scopes)}\n",
      "                if (\n",
      "                    self._jwt_credentials is None\n",
      "                    or additional_claims != self._jwt_credentials.additional_claims\n",
      "                ):\n",
      "                    self._jwt_credentials = jwt.Credentials.from_signing_credentials(\n",
      "                        self, None, additional_claims=additional_claims\n",
      "                    )\n",
      "        elif not self._scopes and audience:\n",
      "            self._jwt_credentials = jwt.Credentials.from_signing_credentials(\n",
      "                self, audience\n",
      "            )\n",
      "\n",
      "    @_helpers.copy_docstring(credentials.Signing)\n",
      "    def sign_bytes(self, message):\n",
      "        return self._signer.sign(message)\n",
      "\n",
      "    @property  # type: ignore\n",
      "    @_helpers.copy_docstring(credentials.Signing)\n",
      "    def signer(self):\n",
      "        return self._signer\n",
      "\n",
      "    @property  # type: ignore\n",
      "    @_helpers.copy_docstring(credentials.Signing)\n",
      "    def signer_email(self):\n",
      "        return self._service_account_email\n",
      "\n",
      "----------------------------------------\n",
      "Class: Request\n",
      "class Request(transport.Request):\n",
      "    \"\"\"Requests request adapter.\n",
      "\n",
      "    This class is used internally for making requests using various transports\n",
      "    in a consistent way. If you use :class:`AuthorizedSession` you do not need\n",
      "    to construct or use this class directly.\n",
      "\n",
      "    This class can be useful if you want to manually refresh a\n",
      "    :class:`~google.auth.credentials.Credentials` instance::\n",
      "\n",
      "        import google.auth.transport.requests\n",
      "        import requests\n",
      "\n",
      "        request = google.auth.transport.requests.Request()\n",
      "\n",
      "        credentials.refresh(request)\n",
      "\n",
      "    Args:\n",
      "        session (requests.Session): An instance :class:`requests.Session` used\n",
      "            to make HTTP requests. If not specified, a session will be created.\n",
      "\n",
      "    .. automethod:: __call__\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, session=None):\n",
      "        if not session:\n",
      "            session = requests.Session()\n",
      "\n",
      "        self.session = session\n",
      "\n",
      "    def __del__(self):\n",
      "        try:\n",
      "            if hasattr(self, \"session\") and self.session is not None:\n",
      "                self.session.close()\n",
      "        except TypeError:\n",
      "            # NOTE: For certain Python binary built, the queue.Empty exception\n",
      "            # might not be considered a normal Python exception causing\n",
      "            # TypeError.\n",
      "            pass\n",
      "\n",
      "    def __call__(\n",
      "        self,\n",
      "        url,\n",
      "        method=\"GET\",\n",
      "        body=None,\n",
      "        headers=None,\n",
      "        timeout=_DEFAULT_TIMEOUT,\n",
      "        **kwargs\n",
      "    ):\n",
      "        \"\"\"Make an HTTP request using requests.\n",
      "\n",
      "        Args:\n",
      "            url (str): The URI to be requested.\n",
      "            method (str): The HTTP method to use for the request. Defaults\n",
      "                to 'GET'.\n",
      "            body (bytes): The payload or body in HTTP request.\n",
      "            headers (Mapping[str, str]): Request headers.\n",
      "            timeout (Optional[int]): The number of seconds to wait for a\n",
      "                response from the server. If not specified or if None, the\n",
      "                requests default timeout will be used.\n",
      "            kwargs: Additional arguments passed through to the underlying\n",
      "                requests :meth:`~requests.Session.request` method.\n",
      "\n",
      "        Returns:\n",
      "            google.auth.transport.Response: The HTTP response.\n",
      "\n",
      "        Raises:\n",
      "            google.auth.exceptions.TransportError: If any exception occurred.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            _LOGGER.debug(\"Making request: %s %s\", method, url)\n",
      "            response = self.session.request(\n",
      "                method, url, data=body, headers=headers, timeout=timeout, **kwargs\n",
      "            )\n",
      "            return _Response(response)\n",
      "        except requests.exceptions.RequestException as caught_exc:\n",
      "            new_exc = exceptions.TransportError(caught_exc)\n",
      "            six.raise_from(new_exc, caught_exc)\n",
      "\n",
      "----------------------------------------\n",
      "Function: authenticate\n",
      "def authenticate():\n",
      "    #Load .env\n",
      "    load_dotenv()\n",
      "    #DLAI Custom Key\n",
      "    return \"DLAI_CREDENTIALS\", \"DLAI_PROJECT\", \"gs://gcp-sc2-rlhf\"\n",
      "    \n",
      "    #Decode key and store in .JSON\n",
      "    SERVICE_ACCOUNT_KEY_STRING_B64 = os.getenv('SERVICE_ACCOUNT_KEY')\n",
      "    SERVICE_ACCOUNT_KEY_BYTES_B64 = SERVICE_ACCOUNT_KEY_STRING_B64.encode(\"ascii\")\n",
      "    SERVICE_ACCOUNT_KEY_STRING_BYTES = base64.b64decode(SERVICE_ACCOUNT_KEY_BYTES_B64)\n",
      "    SERVICE_ACCOUNT_KEY_STRING = SERVICE_ACCOUNT_KEY_STRING_BYTES.decode(\"ascii\")\n",
      "\n",
      "    SERVICE_ACCOUNT_KEY = json.loads(SERVICE_ACCOUNT_KEY_STRING)\n",
      "\n",
      "\n",
      "    # Create credentials based on key from service account\n",
      "    # Make sure your account has the roles listed in the Google Cloud Setup section\n",
      "    credentials = Credentials.from_service_account_info(\n",
      "        SERVICE_ACCOUNT_KEY,\n",
      "        scopes=['https://www.googleapis.com/auth/cloud-platform'])\n",
      "\n",
      "    if credentials.expired:\n",
      "        credentials.refresh(Request())\n",
      "    \n",
      "    #Set project ID according to environment variable    \n",
      "    PROJECT_ID = os.getenv('PROJECT_ID')\n",
      "    STAGING_BUCKET = os.getenv('STAGING_BUCKET')# 'gs://gcp-sc2-rlhf-staging'\n",
      "    \n",
      "    return credentials, PROJECT_ID, STAGING_BUCKET\n",
      "\n",
      "----------------------------------------\n",
      "Function: load_dotenv\n",
      "def load_dotenv(\n",
      "    dotenv_path: Optional[StrPath] = None,\n",
      "    stream: Optional[IO[str]] = None,\n",
      "    verbose: bool = False,\n",
      "    override: bool = False,\n",
      "    interpolate: bool = True,\n",
      "    encoding: Optional[str] = \"utf-8\",\n",
      ") -> bool:\n",
      "    \"\"\"Parse a .env file and then load all the variables found as environment variables.\n",
      "\n",
      "    Parameters:\n",
      "        dotenv_path: Absolute or relative path to .env file.\n",
      "        stream: Text stream (such as `io.StringIO`) with .env content, used if\n",
      "            `dotenv_path` is `None`.\n",
      "        verbose: Whether to output a warning the .env file is missing.\n",
      "        override: Whether to override the system environment variables with the variables\n",
      "            from the `.env` file.\n",
      "        encoding: Encoding to be used to read the file.\n",
      "    Returns:\n",
      "        Bool: True if at least one environment variable is set else False\n",
      "\n",
      "    If both `dotenv_path` and `stream` are `None`, `find_dotenv()` is used to find the\n",
      "    .env file.\n",
      "    \"\"\"\n",
      "    if dotenv_path is None and stream is None:\n",
      "        dotenv_path = find_dotenv()\n",
      "\n",
      "    dotenv = DotEnv(\n",
      "        dotenv_path=dotenv_path,\n",
      "        stream=stream,\n",
      "        verbose=verbose,\n",
      "        interpolate=interpolate,\n",
      "        override=override,\n",
      "        encoding=encoding,\n",
      "    )\n",
      "    return dotenv.set_as_environment_variables()\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "members = inspect.getmembers(utils)\n",
    "\n",
    "for name, member in members:\n",
    "    if inspect.isfunction(member):\n",
    "        print(f\"Function: {name}\")\n",
    "        print(inspect.getsource(member))\n",
    "        print(\"-\" * 40)  # Separator between functions\n",
    "\n",
    "    elif inspect.isclass(member):\n",
    "        print(f\"Class: {name}\")\n",
    "        print(inspect.getsource(member))\n",
    "        print(\"-\" * 40)  # Separator between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf92aac",
   "metadata": {},
   "source": [
    "## Run the pipeline job on Vertex AI\n",
    "\n",
    "Now that we have created our dictionary of values, we can create a PipelineJob. This just means that the RLHF pipeline will execute on Vertex AI. So it's not running locally here in the notebook, but on some server on Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba1642b4-d16d-4e9b-ba87-3391168c5a11",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "427dc778-9a04-4816-8569-0b5ea1c39f14",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID,\n",
    "                location = REGION,\n",
    "                credentials = credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3eac3e3-2d17-47d7-b69f-97a20e91042b",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rlhf_pipeline.yaml'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the path for the YAML file\n",
    "RLHF_PIPELINE_PKG_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa58dce",
   "metadata": {},
   "source": [
    "- This job takes about a full day to run with multiple accelerators (TPUs/GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc41fc3",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"tutorial-rlhf-tuning\",\n",
    "    pipeline_root=STAGING_BUCKET,\n",
    "    template_path=RLHF_PIPELINE_PKG_PATH,\n",
    "    parameter_values=parameter_values)\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd6e1e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Fine Tune LLM with RLHF.ipynb'   __pycache__   rlhf_pipeline.yaml   utils.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
